{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "995f6dd8",
   "metadata": {},
   "source": [
    "### Import bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49d00d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad value in file PosixPath('/Users/tomasz/.matplotlib/stylelib/company.mplstyle'), line 3 (\"axes.prop_cycle: cycler('color', ['#123D98', '#C21E3C', '#E2A713', '#00AEEF', '#7F3F98'])\"): Key axes.prop_cycle: \"cycler('color', ['\" is not a valid cycler construction: unterminated string literal (detected at line 1) (<unknown>, line 1)\n",
      "Bad value in file PosixPath('/Users/tomasz/.matplotlib/stylelib/company.mplstyle'), line 6 ('grid.color: #e0e0e0'): Key grid.color: '' does not look like a color arg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "439f9685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Ładowanie danych\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Podział danych na zbiór treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Inicjalizacja i trenowanie modelu\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predykcja na zbiorze testowym\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb6ef2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f1640ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "399fcf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macierz błędów:\n",
      "[[ 61   2]\n",
      " [  2 106]]\n"
     ]
    }
   ],
   "source": [
    "# Obliczanie macierzy błędów\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Macierz błędów:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12c148ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m     fig.update_layout(width=\u001b[32m400\u001b[39m, height=\u001b[32m400\u001b[39m, title=\u001b[33m'\u001b[39m\u001b[33mConfusion Matrix\u001b[39m\u001b[33m'\u001b[39m, font_size=\u001b[32m16\u001b[39m)\n\u001b[32m     10\u001b[39m     fig.show()\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43mplot_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcm\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mplot_confusion_matrix\u001b[39m\u001b[34m(cm)\u001b[39m\n\u001b[32m      7\u001b[39m fig = ff.create_annotated_heatmap(z=cm.values, x=\u001b[38;5;28mlist\u001b[39m(cm.columns), y=\u001b[38;5;28mlist\u001b[39m(cm.index), \n\u001b[32m      8\u001b[39m                                   colorscale=\u001b[33m'\u001b[39m\u001b[33mice\u001b[39m\u001b[33m'\u001b[39m, showscale=\u001b[38;5;28;01mTrue\u001b[39;00m, reversescale=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      9\u001b[39m fig.update_layout(width=\u001b[32m400\u001b[39m, height=\u001b[32m400\u001b[39m, title=\u001b[33m'\u001b[39m\u001b[33mConfusion Matrix\u001b[39m\u001b[33m'\u001b[39m, font_size=\u001b[32m16\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ML_DL_Python_Comarch/.venv/lib/python3.13/site-packages/plotly/basedatatypes.py:3420\u001b[39m, in \u001b[36mBaseFigure.show\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3387\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3388\u001b[39m \u001b[33;03mShow a figure using either the default renderer(s) or the renderer(s)\u001b[39;00m\n\u001b[32m   3389\u001b[39m \u001b[33;03mspecified by the renderer argument\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3416\u001b[39m \u001b[33;03mNone\u001b[39;00m\n\u001b[32m   3417\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3418\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpio\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3420\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ML_DL_Python_Comarch/.venv/lib/python3.13/site-packages/plotly/io/_renderers.py:415\u001b[39m, in \u001b[36mshow\u001b[39m\u001b[34m(fig, renderer, validate, **kwargs)\u001b[39m\n\u001b[32m    410\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    411\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    412\u001b[39m     )\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nbformat \u001b[38;5;129;01mor\u001b[39;00m Version(nbformat.__version__) < Version(\u001b[33m\"\u001b[39m\u001b[33m4.2.0\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    416\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    417\u001b[39m     )\n\u001b[32m    419\u001b[39m display_jupyter_version_warnings()\n\u001b[32m    421\u001b[39m ipython_display.display(bundle, raw=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mValueError\u001b[39m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
     ]
    }
   ],
   "source": [
    "import plotly.figure_factory as ff\n",
    "\n",
    "def plot_confusion_matrix(cm):\n",
    "    cm = cm[::-1]\n",
    "    cm = pd.DataFrame(cm, columns=['pred_0', 'pred_1'], index=['true_1', 'true_0'])\n",
    "\n",
    "    fig = ff.create_annotated_heatmap(z=cm.values, x=list(cm.columns), y=list(cm.index), \n",
    "                                      colorscale='ice', showscale=True, reversescale=True)\n",
    "    fig.update_layout(width=400, height=400, title='Confusion Matrix', font_size=16)\n",
    "    fig.show()\n",
    "\n",
    "plot_confusion_matrix(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac844014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80a1f05a",
   "metadata": {},
   "source": [
    "# Metryki używane do oceny modeli klasyfikacyjnych"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d452aa",
   "metadata": {},
   "source": [
    "## Metryki - Klasyfikacja binarna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342f8c3e",
   "metadata": {},
   "source": [
    "### Macierz błędów (Confusion Matrix)\n",
    "\n",
    "Macierz błędów to tabela, która przedstawia wyniki przewidywań modelu w porównaniu do rzeczywistych klas. W przypadku klasyfikacji binarnej macierz ma postać 2x2 i zawiera cztery główne komponenty:\n",
    "\n",
    "- **True Positives (TP)**: Liczba poprawnie sklasyfikowanych pozytywnych przypadków.\n",
    "- **True Negatives (TN)**: Liczba poprawnie sklasyfikowanych negatywnych przypadków.\n",
    "- **False Positives (FP)**: Liczba negatywnych przypadków, które zostały błędnie sklasyfikowane jako pozytywne.\n",
    "- **False Negatives (FN)**: Liczba pozytywnych przypadków, które zostały błędnie sklasyfikowane jako negatywne."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f42c3f7",
   "metadata": {},
   "source": [
    "![Macierz_pomylek](mp.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb85651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84186d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd271ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0b76a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f73b6cdf",
   "metadata": {},
   "source": [
    "### Dokładność (Accuracy)\n",
    "\n",
    "Dokładność to jedna z najprostszych miar oceny wydajności modelu. Oblicza się ją jako stosunek liczby poprawnych przewidywań do całkowitej liczby próbek:\n",
    "\n",
    "####   $$Accuracy = \\frac{correct\\ predictions}{total\\ predictions} * 100$$\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "$$\n",
    "\n",
    "Dokładność jest przydatna w przypadku zrównoważonych zbiorów danych, ale może być myląca w przypadku niezrównoważonych klas, gdzie jedna klasa dominuje.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7bae70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e091ff97",
   "metadata": {},
   "source": [
    "### Precyzja (Precision)\n",
    "\n",
    "Precyzja mierzy dokładność pozytywnych przewidywań modelu. Jest to stosunek liczby prawdziwie pozytywnych do wszystkich przewidywanych pozytywnych:\n",
    "\n",
    "$$\n",
    "\\text{Precision} = \\frac{TP}{TP + FP}\n",
    "$$\n",
    "\n",
    "Wysoka precyzja oznacza, że model rzadko klasyfikuje negatywne przypadki jako pozytywne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c3f678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e049a11",
   "metadata": {},
   "source": [
    "### Czułość (Recall)\n",
    "\n",
    "Czułość, znana również jako współczynnik prawdziwie pozytywny (True Positive Rate), ocenia, ile rzeczywistych pozytywnych przypadków zostało poprawnie wykrytych przez model:\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "Wysoka czułość oznacza, że model skutecznie identyfikuje pozytywne przypadki, minimalizując błędy typu II (False Negatives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbde8a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e93aa89",
   "metadata": {},
   "source": [
    "### Wskaźnik F1 (F1 Score)\n",
    "\n",
    "Wskaźnik F1 to średnia harmoniczna precyzji i czułości, która łączy obie metryki w jedną wartość. Jest szczególnie przydatny w sytuacjach, gdy istnieje potrzeba zrównoważenia między precyzją a czułością:\n",
    "\n",
    "$$\n",
    "F1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$\n",
    "\n",
    "Wskaźnik F1 jest użyteczny, gdy klasy są niezrównoważone i ważne jest, aby zarówno precyzja, jak i czułość były na wysokim poziomie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd41728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e7e2926",
   "metadata": {},
   "source": [
    "### Raport klasyfikacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d06e55a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92d3984c",
   "metadata": {},
   "source": [
    "## Krzywa ROC i AUC\n",
    "\n",
    "Krzywa ROC (Receiver Operating Characteristic) to wykres, który przedstawia zależność między czułością (True Positive Rate) a współczynnikiem fałszywie pozytywnym (False Positive Rate) dla różnych progów decyzyjnych modelu.\n",
    "\n",
    "AUC (Area Under the Curve) to pole pod krzywą ROC, które mierzy zdolność modelu do rozróżniania klas. AUC przyjmuje wartości od 0 do 1:\n",
    "\n",
    "- AUC = 1 oznacza idealny model, który doskonale rozróżnia klasy.\n",
    "- AUC = 0,5 oznacza model losowy, który nie ma zdolności do klasyfikacji.\n",
    "- AUC < 0,5 oznacza model gorzej niż losowy.\n",
    "\n",
    "Przykład interpretacji: Model ma AUC równe 0,85, co oznacza, że model ma dobrą zdolność do rozróżniania klas. Innymi słowy, prawdopodobieństwo, że model przypisze wyższą wartość prawdopodobieństwa do pozytywnej obserwacji niż do negatywnej, wynosi 0,85."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c1ffce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca13b5a2",
   "metadata": {},
   "source": [
    "## Metryki - Klasyfikacja wieloklasowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e546dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2389f9c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
